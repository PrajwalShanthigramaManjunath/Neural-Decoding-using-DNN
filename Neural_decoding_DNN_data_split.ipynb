{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn\n",
    "# pip install xgboost\n",
    "# pip install keras\n",
    "# pip install sklearn\n",
    "# pip install pandas\n",
    "# pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(pd.read_excel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_x = pd.read_excel('Research data sample.xlsx', sheet_name = 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = pd.read_excel('Research data.xlsx', sheet_name = 'Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column12</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  Column2  Column3  Column4  Column5  Column6  Column7  Column8  \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   Column9  Column10  ...  Column12  Column13  Column14  Column15  Column16  \\\n",
       "0        0         0  ...         0         0         0         0         0   \n",
       "1        0         0  ...         0         0         0         0         0   \n",
       "\n",
       "   Column17  Column18  Column19  Column20  Column21  \n",
       "0         0         0         0         0         0  \n",
       "1         0         0         0         0         1  \n",
       "\n",
       "[2 rows x 21 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Column1', 'Column2', 'Column3', 'Column4', 'Column5', 'Column6',\n",
       "       'Column7', 'Column8', 'Column9', 'Column10', 'Column11', 'Column12',\n",
       "       'Column13', 'Column14', 'Column15', 'Column16', 'Column17', 'Column18',\n",
       "       'Column19', 'Column20', 'Column21'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_y = pd.read_excel('Research data sample.xlsx', sheet_name = 'Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = pd.read_excel('Research data.xlsx', sheet_name = 'Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1\n",
       "0   66.193\n",
       "1   66.193"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y = df_y.rename(columns={'Column1': 'Position'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Position\n",
       "0    66.193\n",
       "1    66.193"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = df_x\n",
    "df_all['Position'] = df_y['Position']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.to_csv('all-combined-data.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "729633"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df_x[0:600000]\n",
    "test_x = df_x[600000:]\n",
    "train_y = df_y[0:600000]\n",
    "test_y = df_y[600000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_all.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# train_x, test_x, train_y, test_y = train_test_split(df_x, df_y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Column2</th>\n",
       "      <th>Column3</th>\n",
       "      <th>Column4</th>\n",
       "      <th>Column5</th>\n",
       "      <th>Column6</th>\n",
       "      <th>Column7</th>\n",
       "      <th>Column8</th>\n",
       "      <th>Column9</th>\n",
       "      <th>Column10</th>\n",
       "      <th>...</th>\n",
       "      <th>Column13</th>\n",
       "      <th>Column14</th>\n",
       "      <th>Column15</th>\n",
       "      <th>Column16</th>\n",
       "      <th>Column17</th>\n",
       "      <th>Column18</th>\n",
       "      <th>Column19</th>\n",
       "      <th>Column20</th>\n",
       "      <th>Column21</th>\n",
       "      <th>Position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66.193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1  Column2  Column3  Column4  Column5  Column6  Column7  Column8  \\\n",
       "0        0        0        1        0        0        0        0        0   \n",
       "1        0        0        0        0        0        0        0        0   \n",
       "\n",
       "   Column9  Column10  ...  Column13  Column14  Column15  Column16  Column17  \\\n",
       "0        0         0  ...         0         0         0         0         0   \n",
       "1        0         0  ...         0         0         0         0         0   \n",
       "\n",
       "   Column18  Column19  Column20  Column21  Position  \n",
       "0         0         0         0         0    66.193  \n",
       "1         0         0         0         1    66.193  \n",
       "\n",
       "[2 rows x 22 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "129633"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying a Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Followed this blogpost: https://towardsdatascience.com/deep-neural-networks-for-regression-problems-81321897ca33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 128)               2944      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 167,809\n",
      "Trainable params: 167,809\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train_x.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_name = 'models/Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.callbacks.callbacks.ModelCheckpoint at 0x2784b236c48>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 22)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600000, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 480000 samples, validate on 120000 samples\n",
      "Epoch 1/50\n",
      "480000/480000 [==============================] - 47s 98us/step - loss: 3.4014 - mean_absolute_error: 3.4014 - val_loss: 0.7946 - val_mean_absolute_error: 0.7946\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79459, saving model to models/Weights-001--0.79459.hdf5\n",
      "Epoch 2/50\n",
      "480000/480000 [==============================] - 45s 94us/step - loss: 2.0663 - mean_absolute_error: 2.0663 - val_loss: 0.5631 - val_mean_absolute_error: 0.5631\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79459 to 0.56310, saving model to models/Weights-002--0.56310.hdf5\n",
      "Epoch 3/50\n",
      "480000/480000 [==============================] - 44s 92us/step - loss: 1.6115 - mean_absolute_error: 1.6115 - val_loss: 2.6539 - val_mean_absolute_error: 2.6539\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.56310\n",
      "Epoch 4/50\n",
      "480000/480000 [==============================] - 45s 94us/step - loss: 1.4118 - mean_absolute_error: 1.4118 - val_loss: 3.2473 - val_mean_absolute_error: 3.2473\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.56310\n",
      "Epoch 5/50\n",
      "480000/480000 [==============================] - 46s 95us/step - loss: 1.3271 - mean_absolute_error: 1.3271 - val_loss: 1.5843 - val_mean_absolute_error: 1.5843\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.56310\n",
      "Epoch 6/50\n",
      "480000/480000 [==============================] - 45s 93us/step - loss: 1.1794 - mean_absolute_error: 1.1794 - val_loss: 1.2692 - val_mean_absolute_error: 1.2692\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.56310\n",
      "Epoch 7/50\n",
      "480000/480000 [==============================] - 45s 94us/step - loss: 1.1201 - mean_absolute_error: 1.1201 - val_loss: 1.5055 - val_mean_absolute_error: 1.5055\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.56310\n",
      "Epoch 8/50\n",
      "480000/480000 [==============================] - 47s 97us/step - loss: 1.0626 - mean_absolute_error: 1.0626 - val_loss: 1.6970 - val_mean_absolute_error: 1.6970\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.56310\n",
      "Epoch 9/50\n",
      "480000/480000 [==============================] - 53s 110us/step - loss: 1.1085 - mean_absolute_error: 1.1085 - val_loss: 0.6951 - val_mean_absolute_error: 0.6951\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.56310\n",
      "Epoch 10/50\n",
      "480000/480000 [==============================] - 44s 92us/step - loss: 0.9913 - mean_absolute_error: 0.9913 - val_loss: 3.1303 - val_mean_absolute_error: 3.1303\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.56310\n",
      "Epoch 11/50\n",
      "480000/480000 [==============================] - 44s 91us/step - loss: 0.9569 - mean_absolute_error: 0.9569 - val_loss: 2.7700 - val_mean_absolute_error: 2.7701\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.56310\n",
      "Epoch 12/50\n",
      "480000/480000 [==============================] - 44s 92us/step - loss: 0.9187 - mean_absolute_error: 0.9188 - val_loss: 0.9904 - val_mean_absolute_error: 0.9904\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.56310\n",
      "Epoch 13/50\n",
      "480000/480000 [==============================] - 45s 94us/step - loss: 0.9329 - mean_absolute_error: 0.9329 - val_loss: 0.5209 - val_mean_absolute_error: 0.5209\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.56310 to 0.52092, saving model to models/Weights-013--0.52092.hdf5\n",
      "Epoch 14/50\n",
      "480000/480000 [==============================] - 45s 94us/step - loss: 0.8838 - mean_absolute_error: 0.8838 - val_loss: 0.5135 - val_mean_absolute_error: 0.5135\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.52092 to 0.51346, saving model to models/Weights-014--0.51346.hdf5\n",
      "Epoch 15/50\n",
      "480000/480000 [==============================] - 44s 91us/step - loss: 0.8733 - mean_absolute_error: 0.8733 - val_loss: 0.9182 - val_mean_absolute_error: 0.9182\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.51346\n",
      "Epoch 16/50\n",
      "480000/480000 [==============================] - 44s 91us/step - loss: 0.8602 - mean_absolute_error: 0.8602 - val_loss: 0.2344 - val_mean_absolute_error: 0.2344\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.51346 to 0.23438, saving model to models/Weights-016--0.23438.hdf5\n",
      "Epoch 17/50\n",
      "480000/480000 [==============================] - 43s 90us/step - loss: 0.8368 - mean_absolute_error: 0.8368 - val_loss: 0.2647 - val_mean_absolute_error: 0.2647\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.23438\n",
      "Epoch 18/50\n",
      "480000/480000 [==============================] - 41s 85us/step - loss: 0.8279 - mean_absolute_error: 0.8279 - val_loss: 0.9932 - val_mean_absolute_error: 0.9932\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.23438\n",
      "Epoch 19/50\n",
      "480000/480000 [==============================] - 40s 83us/step - loss: 0.7879 - mean_absolute_error: 0.7879 - val_loss: 0.6901 - val_mean_absolute_error: 0.6901\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.23438\n",
      "Epoch 20/50\n",
      "480000/480000 [==============================] - 40s 84us/step - loss: 0.8105 - mean_absolute_error: 0.8105 - val_loss: 0.0983 - val_mean_absolute_error: 0.0983\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.23438 to 0.09834, saving model to models/Weights-020--0.09834.hdf5\n",
      "Epoch 21/50\n",
      "480000/480000 [==============================] - 42s 88us/step - loss: 0.7628 - mean_absolute_error: 0.7628 - val_loss: 0.2201 - val_mean_absolute_error: 0.2201\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.09834\n",
      "Epoch 22/50\n",
      "480000/480000 [==============================] - 40s 84us/step - loss: 0.7300 - mean_absolute_error: 0.7300 - val_loss: 0.3142 - val_mean_absolute_error: 0.3142\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.09834\n",
      "Epoch 23/50\n",
      "480000/480000 [==============================] - 40s 84us/step - loss: 0.7150 - mean_absolute_error: 0.7150 - val_loss: 1.6405 - val_mean_absolute_error: 1.6405\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.09834\n",
      "Epoch 24/50\n",
      "480000/480000 [==============================] - 42s 89us/step - loss: 0.7318 - mean_absolute_error: 0.7318 - val_loss: 0.2550 - val_mean_absolute_error: 0.2550\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.09834\n",
      "Epoch 25/50\n",
      "480000/480000 [==============================] - 45s 93us/step - loss: 0.7292 - mean_absolute_error: 0.7292 - val_loss: 1.2348 - val_mean_absolute_error: 1.2348\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.09834\n",
      "Epoch 26/50\n",
      "480000/480000 [==============================] - 45s 93us/step - loss: 0.6878 - mean_absolute_error: 0.6878 - val_loss: 0.6977 - val_mean_absolute_error: 0.6977\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.09834\n",
      "Epoch 27/50\n",
      "480000/480000 [==============================] - 45s 93us/step - loss: 0.6581 - mean_absolute_error: 0.6581 - val_loss: 0.5347 - val_mean_absolute_error: 0.5347\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.09834\n",
      "Epoch 28/50\n",
      "480000/480000 [==============================] - 43s 89us/step - loss: 0.6452 - mean_absolute_error: 0.6452 - val_loss: 0.2183 - val_mean_absolute_error: 0.2183\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.09834\n",
      "Epoch 29/50\n",
      "480000/480000 [==============================] - 45s 94us/step - loss: 0.6168 - mean_absolute_error: 0.6168 - val_loss: 1.1514 - val_mean_absolute_error: 1.1514\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.09834\n",
      "Epoch 30/50\n",
      "480000/480000 [==============================] - 44s 91us/step - loss: 0.6395 - mean_absolute_error: 0.6395 - val_loss: 0.3747 - val_mean_absolute_error: 0.3747\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.09834\n",
      "Epoch 31/50\n",
      "480000/480000 [==============================] - 46s 95us/step - loss: 0.5910 - mean_absolute_error: 0.5910 - val_loss: 0.3176 - val_mean_absolute_error: 0.3176\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.09834\n",
      "Epoch 32/50\n",
      "480000/480000 [==============================] - 46s 96us/step - loss: 0.5884 - mean_absolute_error: 0.5884 - val_loss: 1.2384 - val_mean_absolute_error: 1.2384\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.09834\n",
      "Epoch 33/50\n",
      "480000/480000 [==============================] - 46s 96us/step - loss: 0.5829 - mean_absolute_error: 0.5829 - val_loss: 0.0442 - val_mean_absolute_error: 0.0442\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.09834 to 0.04421, saving model to models/Weights-033--0.04421.hdf5\n",
      "Epoch 34/50\n",
      "480000/480000 [==============================] - 46s 96us/step - loss: 0.5975 - mean_absolute_error: 0.5975 - val_loss: 0.5107 - val_mean_absolute_error: 0.5107\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.04421\n",
      "Epoch 35/50\n",
      "480000/480000 [==============================] - 46s 95us/step - loss: 0.5926 - mean_absolute_error: 0.5926 - val_loss: 0.2033 - val_mean_absolute_error: 0.2033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00035: val_loss did not improve from 0.04421\n",
      "Epoch 36/50\n",
      "480000/480000 [==============================] - 46s 96us/step - loss: 0.5850 - mean_absolute_error: 0.5850 - val_loss: 0.5537 - val_mean_absolute_error: 0.5537\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.04421\n",
      "Epoch 37/50\n",
      "480000/480000 [==============================] - 44s 91us/step - loss: 0.6014 - mean_absolute_error: 0.6014 - val_loss: 0.9613 - val_mean_absolute_error: 0.9613\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.04421\n",
      "Epoch 38/50\n",
      "480000/480000 [==============================] - 48s 100us/step - loss: 0.5679 - mean_absolute_error: 0.5679 - val_loss: 0.5259 - val_mean_absolute_error: 0.5259\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.04421\n",
      "Epoch 39/50\n",
      "480000/480000 [==============================] - 42s 87us/step - loss: 0.5718 - mean_absolute_error: 0.5718 - val_loss: 1.1866 - val_mean_absolute_error: 1.1866\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.04421\n",
      "Epoch 40/50\n",
      "480000/480000 [==============================] - 42s 88us/step - loss: 0.5206 - mean_absolute_error: 0.5206 - val_loss: 0.2165 - val_mean_absolute_error: 0.2165\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.04421\n",
      "Epoch 41/50\n",
      "480000/480000 [==============================] - 41s 84us/step - loss: 0.5285 - mean_absolute_error: 0.5285 - val_loss: 0.2063 - val_mean_absolute_error: 0.2063\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.04421\n",
      "Epoch 42/50\n",
      "480000/480000 [==============================] - 42s 88us/step - loss: 0.5298 - mean_absolute_error: 0.5298 - val_loss: 0.0449 - val_mean_absolute_error: 0.0449\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.04421\n",
      "Epoch 43/50\n",
      "480000/480000 [==============================] - 45s 94us/step - loss: 0.5403 - mean_absolute_error: 0.5403 - val_loss: 0.8563 - val_mean_absolute_error: 0.8563\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.04421\n",
      "Epoch 44/50\n",
      "480000/480000 [==============================] - 44s 92us/step - loss: 0.5307 - mean_absolute_error: 0.5307 - val_loss: 0.3201 - val_mean_absolute_error: 0.3201\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.04421\n",
      "Epoch 45/50\n",
      "480000/480000 [==============================] - 45s 93us/step - loss: 0.5409 - mean_absolute_error: 0.5409 - val_loss: 0.6940 - val_mean_absolute_error: 0.6940\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.04421\n",
      "Epoch 46/50\n",
      "480000/480000 [==============================] - 45s 93us/step - loss: 0.5169 - mean_absolute_error: 0.5169 - val_loss: 0.3011 - val_mean_absolute_error: 0.3011\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.04421\n",
      "Epoch 47/50\n",
      "480000/480000 [==============================] - 40s 84us/step - loss: 0.5418 - mean_absolute_error: 0.5418 - val_loss: 0.4148 - val_mean_absolute_error: 0.4148\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.04421\n",
      "Epoch 48/50\n",
      "480000/480000 [==============================] - 43s 89us/step - loss: 0.5286 - mean_absolute_error: 0.5286 - val_loss: 0.7227 - val_mean_absolute_error: 0.7227\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.04421\n",
      "Epoch 49/50\n",
      "480000/480000 [==============================] - 42s 88us/step - loss: 0.5054 - mean_absolute_error: 0.5054 - val_loss: 0.0898 - val_mean_absolute_error: 0.0898\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.04421\n",
      "Epoch 50/50\n",
      "480000/480000 [==============================] - 43s 90us/step - loss: 0.5333 - mean_absolute_error: 0.5333 - val_loss: 0.0542 - val_mean_absolute_error: 0.0542\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.04421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x27846cc7648>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model.fit(train, target, epochs=50, batch_size=64, validation_split = 0.2, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "wights_file = 'models/Weights-033--0.04421.hdf5' # choose the best checkpoint \n",
    "NN_model.load_weights(wights_file) # load it\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test_x.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = NN_model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([215.47728], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual = test_y.to_numpy()http://localhost:8888/notebooks/deep%20learning/yohan%20(2).ipynb#We-will-judge-our-model-on-Mean-Absolute-Error-Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([215.35])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We will judge our model on Mean Absolute Error Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deep Neural Network validation MAE =  0.041667498268297826\n"
     ]
    }
   ],
   "source": [
    "MAE = mean_absolute_error(actual , predictions)\n",
    "print('Deep Neural Network validation MAE = ', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "# CNN Layers\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(300, 300, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "# COMPILE\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
